<!DOCTYPE HTML>
<html>

<head><meta name="generator" content="Hexo 3.9.0">
	<link rel="bookmark" type="image/x-icon" href="/img/logo_miccall.png">
	<link rel="shortcut icon" href="/img/logo_miccall.png">
	
			    <title>
    chenhaoze.com
    </title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <link rel="stylesheet" href="/css/mic_main.css">
    <link rel="stylesheet" href="/css/dropdownMenu.css">
    <meta name="keywords" content="chenhaoze">
    
    	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	 
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css">
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('/img/wallpaper3.jpg') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script async type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.scrollex.min.js"></script>
    <script src="/js/jquery.scrolly.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
</head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css">
<link rel="stylesheet" href="/css/typo.css">
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="/" class="logo">个人主页</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special">
            <ul class="menu links">
			<!-- Homepage  主页  --> 
			<li>
	            <a href="/" rel="nofollow">主页</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <li class="active">
	            <a href="#s1">分类</a>
	                    <ul class="submenu">
	                        <li>
	                        <a class="category-link" href="/categories/DEEP-LEARNING/">DEEP LEARNING</a></li><li><a class="category-link" href="/categories/练习题/">练习题</a></li><li><a class="category-link" href="/categories/论文/">论文</a></li><li><a class="category-link" href="/categories/随笔/">随笔</a>
	                    </li></ul>
	        </li>
	        
	        <!-- archives  归档   --> 
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/about/" title="关于我">
		                关于我
		            </a>
		        </li>
		        
		        <li>
		            <a href="/gallery/" title="图集">
		                图集
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
                    
			</ul>
</nav>

        <div id="main">
            <div class="post_page_title_img" style="height: 25rem;background-image: url(https://chen950203.github.io/8.png);background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;">
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2>Prediction of dMRI signals</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">
                <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<p><strong>Background:</strong> There is growing interest in the neuroscience community in estimating and mapping microscopic properties of brain tissue non-invasively using magnetic resonance measurements. Machine learning methods are actively investigated to predict the signals measured in diffusion MRI (dMRI).</p>
<p><strong>Methods:</strong> We used different machine learning methods to predict the dMRI data of unknown white matter signals based on the different acquisition parameters and training data. Specifically, we applied the neural architecture search (NAS) to train a recurrent neural network to generate a multilayer perceptron, which can predict dMRI signals of white matter. The search space of NAS is the number of neurons in each layer of the multilayer perceptron network. To our best knowledge, this is the first time to apply NAS to solve the dMRI signal prediction problem.</p>
<p><strong>Results:</strong> Our experiments and results demonstrate that the proposed NAS method can achieve fast training and predict dMRI signals of different acquisition strategies better than other machine learning regression methods, such as support vector regression (SVR), decision tree (DT) and random forest (RF) etc. For the white matter signals with different acquisition strategies of double diffusion encoding (DDE), double oscillating diffusion encoding (DODE), multi-shell and DSI-like pulsed gradient spin-echo (PGSE), the mean squared errors of the multilayer perceptron network designed by NAS are 0.0043, 0.0034, 0.0147 and 0.0199, respectively.</p>
<p><strong>Conclusion:</strong> In this study, neural architecture search was developed for the prediction of dMRI signals and could become an excellent prediction tool.</p>
<p><strong>Keywords:</strong> Diffusion MRI; White Matter Signals; Neural Architecture Search; Regression methods.</p>
<p><strong>I.INTRODUCTION</strong><br>Diffusion magnetic resonance imaging (dMRI) is a key modality to image microstructure of the brain because it is sensitive to cellular architecture at microns. DMRI makes possible inferences of specific microstructural features in the brain, such as neurite density, axonal diameter, axon orientations, cell sizes, and myelin fractions (Enrico <em>et al.</em>, 2016), thus enabling scientific advances of our understanding of normal brain development and aging, and brain disorders.</p>
<p>There are many dMRI techniques to estimate white matter (WM) microstructure, which differ in the target tissue parameters, the modeling strategies, and experimental designs. Many of these techniques are now transitioning from basic research to real biomedical application (Hoy <em>et al.</em>, 2017). However, in order for any of these techniques to become a useful biomedical tool, it is critically important that it is validated to ensure accuracy, precision, and reproducibility (Dyrby <em>et al.</em>, 2018). Since validation faces the challenge of the lack of anatomical ground truth, it is typically performed using simulation data, physical phantoms, and histological data comparison. However, validation has been limited by the number of microstructural indices, the number of algorithms, and the number of acquisitions in the past. Needless to say, the huge hurdle for evaluation exists for creating realistic simulated microstructural environments, or collecting both dMRI and histological data. The two-year ISBI 2019/2020 MRI White Matter Reconstruction Challenge (<a href="https://my.vanderbilt.edu/memento/" target="_blank" rel="noopener">https://my.vanderbilt.edu/memento/</a>) were published, where the first sub-challenge aimed to evaluate the generalizability and appropriateness of three acquisition strategies, such as multi-shell and DSI-like pulsed gradient spin-echo (PGSE) (Stejskal &amp; Tanner, 1965), as well as double diffusion encoding (DDE) (Shemesh <em>et al.</em>, 2010) and double oscillating diffusion encoding (DODE)(Ianuş <em>et al.</em>, 2018). Specifically, a subset of the full dataset and the acquisition parameters are given for each acquisition strategy. The prediction models will be developed to predict the remaining unseen signal using the known signal and acquisition parameters as input.</p>
<p>Machine learning has been an active research topic for many years and led to a lot of successful applications. For example, Shirin et al. applied and built a crop production prediction model using decision tree classification and AdaBoost regression method (Koduri <em>et al.</em>, 2019). Chang et al. presented a new application in the field of rudder test based on a decision tree algorithm (Chang <em>et al.</em>, 2019). The nearest neighborhood component analysis and boosting tree were also used to predict different stages of Alzheimer&#39;s disease (Jin &amp; Deng, 2018). In the past decade, deep neural networks have achieved great success in many challenging applications, such as speech recognition (Hinton <em>et al.</em>, 2012), machine translation(Krizhevsky <em>et al.</em>, 2017) and image recognition (Lecun <em>et al.</em>, 1998), etc. These deep learning techniques have been adapted to medical data analysis and greatly influenced neuroscience community (Marblestone <em>et al.</em>, 2016; Shen1 <em>et al.</em>, 2017). Diagnosis and treatment of diseases with the aid of deep learning have become more common in the medical field. For example, Lim et al. forecasted disease trajectories in Alzheimer&#39;s disease using deep neural networks (Lim &amp; Schaar, 2018). Pereira et al. used convolutional neural networks (CNNs) to accurately segment brain tumor in MRI images (Pereira <em>et al.</em>, 2016; Sergio <em>et al.</em>, 2016). <a href="https://www.sciencedirect.com/science/article/pii/S0169260718308381#!" target="_blank" rel="noopener">Mitra</a> et al. used CNNs to detect Glaucoma and other eye diseases from retinal images more efficiently (Anirban <em>et al.</em>, 2018). Utilizing these developments in machine learning to optimize dMRI acquisition strategies could lead to better generalization of diffusion signal representations.</p>
<p>Despite the quick evolution of various neural network models, often the better the model performance, the stricter the requirements for hyperparameters. The design of neural network structure is also transitioning from the manual design to the automatic design. Google published their work of neural architecture search (NAS) with reinforcement learning (Zoph &amp; Le, 2016). Each NAS framework includes three elements: search space, search method and performance evaluation strategy (Elsken <em>et al.</em>, 2019). The reinforcement learning network using NAS surpassed previously manually designed networks in image classification and language modeling tasks.To our best knowledge, NAS has not been investigated to design models for prediction of WM signals under different acquisition strategies of dMRI. In this paper, we propose a neural network based on NAS to predict white matter signals using the data of the first sub-challenge of ISBI 2019/2020 MRI White Matter Reconstruction Challenge and compare it with several conventional machine learning methods, such as K-Nearest Neighbor (KNN), decision tree (DT) and random forest (RF).</p>
<p><strong>2. Methods</strong></p>
<p><strong>2.1 Data</strong></p>
<p>Data used in this work were provided by ISBI 2019/2020 MRI White Matter Reconstruction Challenge (<a href="https://my.vanderbilt.edu/memento/" target="_blank" rel="noopener">https://my.vanderbilt.edu/memento/</a>). The training data are the measured signals for 5 different tissue configurations with complete details of the acquisition protocol, such as imaging parameters and diffusion gradients properties. The three types of acquisition strategies are multi-shell and DSI-like pulsed gradient spin-echo (<em>PGSE</em>) (Stejskal &amp; Tanner, 1965), double diffusion encoding (<em>DDE</em>) (5) and double oscillating diffusion encoding (<em>DODE</em>) (Ianuş <em>et al.</em>, 2018). The detailed acquisition parameters for each strategy can be found in the corresponding references.</p>
<p>All data were in five voxels, representing five different tissue configurations. The PGSE data were extracted from the MASSIVE dataset (Froeling <em>et al.</em>, 2017), where a healthy human subject was scanned at 3T and five selected voxels included three WM voxels and two gray matter (GM) voxels. The signals measured in each voxel include 2580 unique data points acquired with a multi-shell strategy (PGSE-MS), and 1240 data points acquired with a DSI-like strategy (PGSE-DSI), thus leading to 3820 unique diffusion-weighted volumes in total. The PGSE-MS and PGSE-DSI sequences were performed with different imaging parameters, but with the same diffusion gradients settings. The data of DDE and DODE were sampled in a mouse brain at 16.4 T with 2 different diffusion times and 5 different frequencies, respectively (Ianuş <em>et al.</em>, 2018). All five voxels were from WM. Both uses 5 b-values and 72 directions each, thus leading to 2520 diffusion weighted volumes in total.The dMRI signals of five voxels collected using four different acquisition strategies are shown in Figure 1.<br><img src="//chen950203.github.io/2022/06/23/dmri/1a.png"><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<strong>(a)</strong><br><img src="//chen950203.github.io/2022/06/23/dmri/1b.png"><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<strong>(b)</strong><br><img src="//chen950203.github.io/2022/06/23/dmri/1c.png"><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<strong>(c)</strong><br><img src="//chen950203.github.io/2022/06/23/dmri/1d.png"><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<strong>(d)</strong><br>Fig. 1. dMRI signals of five voxels using different acquisition strategies: a) DDE; b) DODE; c) PGSE-DSI; d) PGSE-MS.<br><br><strong>2.2 Neural Architecture Search (NAS)</strong><br>Deep learning is becoming more and more popular on solving practical problems in different fields. The key step is to model data by designing different types of neural networks such as multilayer perceptron, convolutional neural networks, and recurrent neural networks to achieve classification and regression goals. However, its success is accompanied by the growing demand for network structure design, where manual tuning of complex neural network structures not only is time consuming and expert knowledge demanding, but also may be sub-optimal. Therefore, neural architecture search (NAS) is proposed to automatically design neural network structures with the hope of automating machine learning in the future (Zoph &amp; Le, 2016) for high predictive performance of deep learning models on unseen data.<br>As proposed by (Zoph &amp; Le, 2016), a variable-length string can be generated using a recurrent neural network (RNN) to specify a neural network. We used RNN as a controller to generate a descriptive string of the structure of a multilayer perceptron, and then trained RNN through reinforcement learning to find the optimal multilayer perceptron structure in a given search space. Training the multilayer perceptron network specified by the string on the training dMRI data will result in a mean squared error (MSE) on a validation dMRI set. Using this MSE as the reward signal, we can update the controller by computing the policy gradient.  In other words, the controller will give a higher score to the neural network structure with a lower MSE.<br>2.2.1 Search Space<br>Since the sample data is relatively small, instead of searching in complex network structures, we chose the multilayer perceptron as the child model to search the number of neurons in the multiple fully connected layers using the controller RNN. As shown in Fig. 2, we set 5 different numbers of neurons to choose: 8, 16, 32, 64 and 128. Our goal is to select the neural network model with the highest reward in the search space to achieve the best prediction accuracy, i.e. the least MSE.<br><img src="//chen950203.github.io/2022/06/23/dmri/2.png"><br>Fig. 2. The number of neurons (m) in each layer of the multilayer perceptron are the search space in the proposed NAS. m belongs to [8, 16, 32, 64, 128] in this work.<br>2.2.2 The RNN controller<br>Recurrent neural networks (RNNs) are neural network structures used to process time series with certain memories to remove the content of uninterest and to retain that of interest. RNN contains the input, hidden, and output units, where the output is controlled by the activation function. Long Short-Term Memory (LSTM) is a specific RNN that is designed to address the gradient disappearance during long sequence training and the gradient explosion problem for training of longer sequences. The basic structure of the LSTM unit is shown Fig.3 (Chen et al., 2020).<br>The forget gate can be express as:</p>
<center>$f_t=\sigma(W_f[x_t,h_t, C_{t-1}]+b_t)*C_{t-1}\qquad (1)$</center>
Where, $x_{t}$ is input unit; $h_{t-1}$ is the output unit; $C_{t-1}$ is the status of previous unit; $W_f$ is weight; bt is the bias; σ is the sigmoid. Input gate and output gate can be expressed by formula (2)-(5):
<center>$i_t=\sigma(W_i[x_t,h_{t-1}, C_{t-1}]+b_i)\qquad (2)$</center>

<center>$C_t=f_t+i_t*tanh(W_i[x_t,h_{t-1}, C_{t-1}]+b_i)\qquad (3)$</center>

<center>$o_t=\sigma(W_o[x_t,h_{t-1}, C_t]+b_o)\qquad (4)$</center>

<center>$h_t=tanh(C_t)*o_t\qquad (5)$</center>
where $C_t$ is the output status of the input gate and $h_t$ is the output of the LSTM unit.
![](./dmri/3.png)
Fig. 3. Structure of the LSTM unit. (Reprinted from (22))
We adapted the NASCell unit proposed in (Zoph & Le, 2016) as shown in Fig. 4, which is similar to the aforementioned LSTM unit. The internal calculation steps of NASCell can be expressed as follows:
<center>$a_0=tanh(W_1*x_1+W_2*h_{t-1})\qquad (6)$</center>
<center>$a_1=ReLU((W_3*x_t) \cdot (W_4*h_{t-1}))\qquad (7)$</center>
<center>$a_0=tanh(W_1*x_1+W_2*h_{t-1})\qquad (8)$</center>
<center>$a_0^{new}=ReLU(a_0+c_{t-1})\qquad (9)$</center>
<center>$h_t=sigmoid(a_0^{new} \cdot a_1)\qquad (10)$</center>
<center>$c_t=(W_3*x_t) \cdot (W_4*h_{t-1})\qquad (11)$</center>
where $W_1$ represents the connection weight matrix from the input layer to node $a_0$, $W_2$ represents the connection weight matrix from the hidden layer to node $a_0$. $W_3$ represents the connection weight matrix from the input layer to node $a_1$, and $W_4$ represents the connection weight matrix from the hidden layer to node $a_1$.
![](./dmri/4.png)
Fig. 4. The structure of NASCell for the RNN controller.
2.2.3 Training with reinforcement learning
Reinforcement learning, supervised learning and unsupervised learning are the three branches of machine learning. Reinforcement learning is different from the other two branches by using the reward to guide the agent (the controller RNN in this work) for the maximum cumulative reward. Given   as the parameters of controller RNN and $\theta_c$  as the multilayer perceptron architecture predicted by the controller RNN, the optimal multilayer perceptron model can be obtained by maximizing the expected reward,
<center>$J(\theta_c)=E_{P(\alpha_{1:M;\theta_c})}[R]\qquad (11)$</center>
where $P(a_{1:M;\theta_c})$ is the probability when sampling from   and R is the reward, i.e. the MSE of the validation set as the indicator of accuracy. By evaluating the loss function (MSE) generated by each iteration of the training, reinforcement learning searchs for the minimum MSE value in the predefined search space. Since R is not differentiable, we use the empirical strategy gradient algorithm to update J (Williams, 1992):
<center>$\frac{1}{2}\sum_{k=1}^{n}\sum_{k=1}^{n}\nabla    \theta_clogP(\alpha_1\mid\alpha_{(m-1):1};\theta_c)R_k\qquad (12)$</center>
where n is the number of different multilayer perceptron architectures sampled by the controller RNN in each batch, M is the number of neurons to be predicted in each fully connected neural network layer set by the controller and $R_k$  is the reward of k-th predicted architecture. To suppress the high fluctuation of the estimate, we adapted the baseline function as in (Zoph & Le, 2016) to replace $R_k$ in Eq. 12 with “$R_k-B$”, where B is defined as an exponential moving average of the previous architecture accuracies.
The automatic construction of the optimal multilayer perceptron architecture in the search space can be achieved by the NAS training as shown in the flower chart of Fig. 5.
![](./dmri/5.png)
Fig. 5. Training of Neural Architecture Search. The RNN controller predicts the optimal multilayer perceptron structure in the predefined search space based on the reward.
**3. Results**
**3.1 10-fold cross-validation**
In this experiment, the dMRI data obtained by four different collection strategies are divided into training set and validation data. Here, due to the small amount of experimental data and in order to avoid over-learning and under-learning, we used 10-fold cross-validation (CV) of the sample data to evaluate all methods, which selected 90% data for training and 10% for validation and repeated 10 times for 10 non-overlap validation data sets. The MSE averaged over 10 trials was used as the quantitative metric, unless otherwise stated.
**3.2 Feature selection for conventional machine learning methods**
In machine learning, the dimensionality of input features affects the accuracy of the prediction models. Here, we compare full features, manually selected features, and principal components (PCs) from principal component analysis (PCA). The manually selected features were obtained by removing the constant input parameters in each dMRI strategy as shown in Table 1. As can be seen in Fig. 6, the first PC accounts more than 99.9% of the total variance for PGSE-DSI and PGSE-MS, and the first six PCs account more than 99.9% of the total variance for DDE and DODE. 
In order to evaluate which feature set can achieve the better prediction performance, we chose support vector machine regression (SVR) (Chang, 2011), decision tree (DT) (Breiman et al., 1983), random forest (RF) (Breiman, 2001), k-nearest neighbors (KNN) (Altman, 1992), adaboost regressor (AR) (Drucker, 1997), gradient boosting regressor (GBR) (Friedman, 2001) and extra-trees regressor (ET) (Geurts et al., 2006) as the regression model. Since the aim of the experiment was only to compare the advantages and disadvantages between different features, the default parameters were used for these regressors. These parameters can be found in a supplementary appendix online.
Fig. 7 show the MSE values for different methods using full features, PCs and manually selected features, respectively. In these figures, a smaller MSE value denotes a more accurate prediction performance. Since SVR seemed to have almost one-order of magnitude larger MSE than the other methods, we plotted it in a different color and used a larger scale for the vertical axis. We can also see from Fig. 7 that no matter which collection strategy was adopted, use of full features is more effective than PCA and manually selected features regardless of the regression model used. PCA did not help prediction performance, except for SVR of DODE. Full features lead to better MSE values than manually selected features in 18 out of 24 combinations (the number of acquisition methods x the number of regression methods excluding SVR). The MSE value averaged over 24 combinations is 1.527x10-2 for full features and 1.555 x10-2 that for manually selected features. The manual feature selection is marginally inferior to use of all features. It seems that, manual feature selection did not offer any advantage for prediction since the maximum number of features is relatively small (19). Furthermore, each PC is a linear combination of the original features, i.e. different parameters in the acquisition strategy, such as the gradient strength and its x, y and z components etc. So PCA mixes the original input parameters, which may not be helpful to reduce input parameters. Therefore, in the subsequent experiments, all features were used as model inputs for machine learning methods.
![](./dmri/6.png)
Fig. 6. Principal component analysis (PCA) of the feature space.
Table 1 Manually selected input features：& cross;  represents the manually selected variable parameters; × represents the eliminated constant parameters
![](./dmri/b1.png)

<p><img src="//chen950203.github.io/2022/06/23/dmri/7.png"><br>Fig. 7. MSE for different prediction methods using different input features (all features, PCs, and manual selected features) a) DDE; b) DODE; c) PGSE-DSI; d) PGSE-MS.<br>We also investigated whether the normalization of input features affects the accuracy of dMRI signal prediction. We normalized each input feature into the range of [0 1]. The dMRI signals were predicted using the KNN for four acquisition strategies with and without normalization using 10-fold CV. The results are shown in Table 2. Normalizing the data had a similar prediction performance as without normalization. Therefore, in all subsequent experiments, we did not normalize the acquisition parameters for results reported in this work.<br>For NAS, since neural networks have the ability to extract features automatically, we used all features appearing in Table 1 as input variables.<br>Table 2 10-fold CV MSE for unnormalized and normalized features.<br><img src="//chen950203.github.io/2022/06/23/dmri/b2.png"><br>Table 3 Mean squared errors (MSE) of the MLP with different depths on the validation data set.<br><img src="//chen950203.github.io/2022/06/23/dmri/b3.png"><br><strong>3.3 Prediction performance</strong><br>We conducted additional experiments using MLP of 10, 13, 16, 19, and 22 layers (with hyperparameters optimized by NAS). The MSE values on the validation set from these MLP are listed in Table 3, which are worse than that of RNN-optimized 7-layer MLP, more substantially for DDE/DODE. The more complex the network, the worse performance. This may indicate the overfitting of MLP deeper than 7 layers. Therefore, 7 was used as the maximum layer of MLP as the state space of NSA for the following experiments.<br>The number of cells in RNN controller was 32 and the batch size of the child models was 64. The dimension of the output space for each layer of the 7-layer perceptron will be selected among (8, 16, 32, 64, 128) to get the least MSE via the gradient method which described in 3.3 section. Table 4 lists the parameter space for NAS.<br><img src="//chen950203.github.io/2022/06/23/dmri/8.png"><br>Fig. 8. The loss curves of NAS for training and validation data<br>As can be seen from Fig. 8, during the training process, the loss values of training and validation data converged quickly, and no overfitting was observed for 200 epochs. Therefore, we set the number of training epochs to 200. The parameters of multilayer perceptron network optimized by NAS are shown in Table 5. Note that the number of layers was fixed as 7 and only the number of neurons in each layer was searched. The results of predicting dMRI signals by NAS of 7-layer perceptron network are shown in Fig. 9, from which we can see that the signals predicted by NAS match the original ones well for different acquisition strategies. Since the goal of this study to investigate the effectiveness of machine learning methods on quantitative prediction of dMRI data with different acquisition protocols, we focused on the quantitative accuracy evaluated by MSE (see Table 6). Nevertheless, we applied our NAS model on all image voxels (provided by the challenge organizer and not used in the training and validation process) and provided a set of typical images in Fig. 10. Our model is able to predict hundreds or thousands of these images that can be used for further calculation of diffusion parameters or WM tractography.<br>Table 4 Neural architecture search (NAS) parameters<br><img src="//chen950203.github.io/2022/06/23/dmri/b4.png"><br><img src="//chen950203.github.io/2022/06/23/dmri/9.png"><br>Fig. 9. The prediction results for different dMRI strategies through NAS: a) DDE; b) DODE; c) PGSE-DSI; d) PGSE-MS<br><img src="//chen950203.github.io/2022/06/23/dmri/10.png"><br>Fig. 10. One brain image slice (top: mouse; bottom: human) predicted by NAS for different dMRI acquisition strategies: a) DDE; b) DODE; c) PGSE-DSI; d) PGSE-MS.<br>Table 5 The parameters for 7-layer perceptron network optimized by NAS for different acquisition strategies.</p>

            </div>

            <!-- Post Comments -->
            
    <!-- 使用 DISQUS_CLICK -->
<div id="disqus-comment">
    <div id="disqus_thread"></div>

<!-- add animation -->
<style>
	.disqus_click_btn {
            line-height: 30px;
            margin: 0;
            min-width: 50px;
            padding: 0 14px;
            display: inline-block;
            font-family: "Roboto", "Helvetica", "Arial", sans-serif;
            font-size: 14px;
            font-weight: 400;
            text-transform: uppercase;
            letter-spacing: 0;
            overflow: hidden;
            will-change: box-shadow;
            transition: box-shadow .2s cubic-bezier(.4, 0, 1, 1), background-color .2s cubic-bezier(.4, 0, .2, 1), color .2s cubic-bezier(.4, 0, .2, 1);
            outline: 0;
            cursor: pointer;
            text-decoration: none;
            text-align: center;
            vertical-align: middle;
            border: 0;
            background: rgba(158, 158, 158, .2);
            box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
            color: #fff;
            background-color: #7EC0EE;
            text-shadow: 0
        }
</style>
	
<div class="btn_click_load" id="disqus_bt"> 
    <button class="disqus_click_btn">点击查看评论</button>
</div>

<!--
<script type="text/javascript">
$('.btn_click_load').click(function() {
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'http-chen950203-github-io'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    document.getElementById('disqus_bt').style.display = "none";
});
</script>
-->
<script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'http://chen950203.github.io/2022/06/23/dmri/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'http://chen950203.github.io/2022/06/23/dmri/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>

<script type="text/javascript">
    $('.btn_click_load').click(function() {  //click to load comments
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document;
            var s = d.createElement('script');
            s.src = '//http-chen950203-github-io.disqus.com/embed.js';
            s.setAttribute('data-timestamp', + new Date());
            (d.head || d.body).appendChild(s);
        })();
        $('.btn_click_load').css('display','none');
    });
</script>
</div>
<style>
    #disqus-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
                <li>Design: <a href="http://chen950203.github.io " style="border-bottom: none;">陈昊泽</a></li>
            </ul>
            
                <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			
        </div>
    </div>
</body>



 	
</html>
